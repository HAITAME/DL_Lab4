# Deep Learning Lab 4

This repository contains code for a deep learning lab assignment focused on implementing various architectures using PyTorch, including Autoencoders (AE), Variational Autoencoders (VAE), and Generative Adversarial Networks (GANs). The lab involves training these models on different datasets and evaluating their performance.

## Contents

1. [Introduction](#introduction)
2. [Part 1: AE and VAE](#part-1-ae-and-vae)
3. [Part 2: GANs](#part-2-gans)
4. [Conclusion](#conclusion)

## Introduction

The main objective of this lab is to familiarize students with PyTorch library and deep learning concepts by implementing and training various neural network architectures. The lab is divided into two parts: AE and VAE, and GANs. Each part involves designing the architecture, training the model, evaluating its performance, and analyzing the results.

## Part 1: AE and VAE

In this part, we implement Autoencoder (AE) and Variational Autoencoder (VAE) architectures and train them on the MNIST dataset. We specify hyperparameters such as learning rate, batch size, and number of epochs, and evaluate the models by plotting loss curves and analyzing additional metrics like KL divergence. Latent space visualization is also performed to understand feature representations.

## Part 2: GANs

This part focuses on implementing a Generative Adversarial Network (GAN) architecture and training it on the Abstract Art Gallery dataset. We define the Generator and Discriminator architectures, configure data loaders, and optimize the models using appropriate loss functions and optimizers. Evaluation involves plotting loss curves for Generator and Discriminator, and generating new data for comparison with the original dataset.

## Conclusion

This lab provides valuable hands-on experience with PyTorch and deep learning concepts, including autoencoders, variational autoencoders, and generative adversarial networks. By completing this lab, students gain practical skills in designing neural network architectures, training models, evaluating performance, and analyzing results, which are essential for further study and research in the field of deep learning.


